{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import toad\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#解决输出结果展示不全问题\n",
    "pd.set_option('max_row',350)\n",
    "pd.set_option('max_columns', 200)\n",
    "\n",
    "#同时展示多个结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型结果展示\n",
    "#等频展示\n",
    "def report_train(pred, y, k=10):\n",
    "    bins, cut = pd.qcut(pred,k,retbins=True, duplicates='drop')\n",
    "    df = pd.crosstab(bins,y).sort_index(ascending=False)\n",
    "    df['total'] = df[0]+df[1] \n",
    "    df['1_%'] = df[1]/df['total']\n",
    "    df['KS'] = abs(df[1].cumsum()/df[1].sum()-df[0].cumsum()/df[0].sum())\n",
    "    return df,cut\n",
    "\n",
    "def report_test(pred, y, cut):\n",
    "    df = pd.crosstab(pd.cut(pred,cut),y).sort_index(ascending=False)\n",
    "    df['total'] = df[0]+df[1] \n",
    "    df['1_%'] = df[1]/df['total']\n",
    "    df['KS'] = abs(df[1].cumsum()/df[1].sum()-df[0].cumsum()/df[0].sum())\n",
    "    return df\n",
    "\n",
    "#等距展示\n",
    "def report_dis(pred, y, cut):\n",
    "    df = pd.crosstab(pd.cut(pred,cut),y).sort_index(ascending=False)\n",
    "    df['total'] = df[0]+df[1] \n",
    "    df['1_%'] = df[1]/df['total']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def binary_metric(target, pred, threshold=0.5):\n",
    "    '''\n",
    "    ---二分类数据模型评价函数---\n",
    "    target: 样本真实标签\n",
    "    pred: 样本预测概率值\n",
    "    threshold: 概率阈值\n",
    "    '''\n",
    "    pred_ = (pred>=threshold)*1\n",
    "    accuracy = accuracy_score(target, pred_)     #accuracy_score准确率\n",
    "    precision = precision_score(target, pred_)   #precision_score精确率\n",
    "    recall = recall_score(target, pred_)         #recall_score召回率\n",
    "    f1_measure = f1_score(target, pred_)         #f1_score  f1得分\n",
    "    confusionMatrix = confusion_matrix(target, pred_)     #confusion_matrix  混淆矩阵\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred, pos_label=1)   #roc_curve ROC曲线\n",
    "    auc = roc_auc_score(target, pred)     #roc_auc_score  AUC面积\n",
    "    KS = max(abs(tpr-fpr))\n",
    "    TP = confusionMatrix[1, 1]\n",
    "    FP = confusionMatrix[0, 1]\n",
    "    FN = confusionMatrix[1, 0]\n",
    "    TN = confusionMatrix[0, 0]\n",
    "    lift = (TP/(TP+FP))/((TP+FN)/(TP+FP+FN+TN))\n",
    "    MAP = average_precision_score(target, pred)    #average_precision_score\n",
    "\n",
    "    print (\"------------------------- \")\n",
    "    print (\"confusion matrix:\")\n",
    "    print (\"------------------------- \")\n",
    "    print (\"| TP: %5d | FP: %5d |\" % (confusionMatrix[1, 1], confusionMatrix[0, 1]))\n",
    "    print (\"----------------------- \")\n",
    "    print (\"| FN: %5d | TN: %5d |\" % (confusionMatrix[1, 0], confusionMatrix[0, 0]))\n",
    "    print (\" ------------------------- \")\n",
    "    print (\"Accuracy:       %.2f%%\" % (accuracy * 100))\n",
    "    print (\"Recall:         %.2f%%\" % (recall * 100))\n",
    "    print (\"Precision:      %.2f%%\" % (precision * 100))\n",
    "    print (\"F1-measure:     %.2f%%\" % (f1_measure * 100))\n",
    "    print (\"AUC:            %.2f%%\" % (auc * 100))\n",
    "    print (\"KS:             %.2f%%\" % (KS * 100))\n",
    "    print (\"lift:           %.2f%%\" % (lift * 100))\n",
    "    print (\"MAP:            %.2f%%\" % (MAP * 100))\n",
    "    print (\"------------------------- \")\n",
    "    # return (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取\n",
    "df_220412 = pd.read_csv(r'数据文件.csv', encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除无意义字段\n",
    "df_220412 = df_220412.drop(['xx字段', 'xx_字段'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除缺失率>=0.9的字段\n",
    "df_220412 = df_220412.drop(list(df_220412.isnull().mean()[df_220412.isnull().mean()>=0.9].index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除同一值占比过高字段\n",
    "def qu_tyz(data, var_not, a=0.9):\n",
    "    all_var=data.columns\n",
    "    sd=data.shape[0]\n",
    "    zs_var=list(set(all_var)-set(var_not))\n",
    "    paichu=[]\n",
    "    for i in zs_var:\n",
    "        c=max(data[i].value_counts())\n",
    "        if c/sd>a:\n",
    "            paichu.append(i)\n",
    "    var_drop=paichu\n",
    "    return var_drop\n",
    "\n",
    "var_drop = qu_tyz(df_220412, var_not=['lable'], a=0.9)\n",
    "var_drop\n",
    "df_220412 = df_220412.drop(var_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别型变量编码(使用坏账率编码)\n",
    "def char_encoding(df, vars, target):\n",
    "    '''\n",
    "    ---以每个类别对应的坏账率替换替换相应类别---\n",
    "    df: 数据源\n",
    "    vars: 需要转换的类别变量列表\n",
    "    target: 好坏标签变量\n",
    "    '''\n",
    "    for var in vars:\n",
    "        char_info = df.groupby([var])[target].agg(['sum','count'])\n",
    "        char_info['rate'] = char_info['sum']/char_info['count']\n",
    "        df[var] = df[var].map(char_info['rate'])\n",
    "    return df\n",
    "\n",
    "vars = ['类别字段名列表']\n",
    "\n",
    "df_encode = char_encoding(df_220412, vars=vars, target='lable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分层抽样划分训练测试集\n",
    "train, test=train_test_split(df_encode, test_size=0.3, stratify=df_encode['lable'], random_state=1234)\n",
    "x_train = train.drop('lable', axis=1)\n",
    "y_train = train['lable']\n",
    "x_test = test.drop('lable', axis=1)\n",
    "y_test = test['lable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"boostrt\":\"gbtree\",\n",
    "       \"objective\":\"binary:logistic\",\n",
    "       \"gamma\":0.4, #节点最小分裂损失\n",
    "       \"min_child_weight\":0.1, #叶子节点最小权重和\n",
    "       \"alpha\":1, #L1正则项权重\n",
    "       \"lambda\":4,#L2正则项权重\n",
    "       \"subsample\":0.7, #样本随机比例\n",
    "       \"colsampel_bytree\":0.7, #特征随机比例\n",
    "       \"scale_pos_weight\":8,\n",
    "       \"silent\":1,\n",
    "       \"eta\":0.1, #学习速率\n",
    "       \"seed\":1000,\n",
    "       \"nthread\":-1,\n",
    "       \"eval_metric\":\"auc\",\n",
    "       \"max_depth\":3 #树的最大深度\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_val=xgb.DMatrix(x_test,label=y_test)\n",
    "xgb_train=xgb.DMatrix(x_train,label=y_train)\n",
    "xgb_test=xgb.DMatrix(x_test)\n",
    "\n",
    "plst=list(params.items())\n",
    "num_rounds=200\n",
    "watchlist=[(xgb_train,\"train\"),(xgb_val,\"val\")]\n",
    "\n",
    "model=xgb.train(plst,xgb_train, num_rounds, watchlist, early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征重要性展示\n",
    "importance_ = model.get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame(index=list(importance_.keys()))\n",
    "importance_df['importance'] = list(importance_.values())\n",
    "importance_df.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练预测结果展示\n",
    "pred_train = model.predict(xgb_train)\n",
    "pred_test = model.predict(xgb_val)\n",
    "\n",
    "train_report, cut = report_train(pred_train, y_train['lable'], k=10)\n",
    "test_report = report_test(pred_test, y_test['lable'], cut)\n",
    "train_report\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_metric(y_train['lable'], pred_train, threshold=0.115)\n",
    "binary_metric(y_test['lable'], pred_test, threshold=0.115)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
